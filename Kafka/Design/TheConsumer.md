
# Consumatorul

Consumatorul Kafka funcționează emițând cereri de „fetch” către brokerii care conduc partițiile pe care dorește să le consume. Consumatorul specifică offsetul său în jurnal cu fiecare cerere și primește înapoi o porțiune de jurnal începând de la acea poziție. Consumatorul are astfel un control semnificativ asupra acestei poziții și poate să o deruleze înapoi pentru a reconsuma date dacă este necesar.

## Push vs. Pull
O întrebare inițială pe care am luat-o în considerare este dacă consumatorii ar trebui să preia date de la brokeri sau brokerii ar trebui să trimită date consumatorului. În acest sens, Kafka urmează un design mai tradițional, împărtășit de majoritatea sistemelor de mesagerie, unde datele sunt împinse la broker de către producător și trase de broker de consumator. Unele sisteme axate pe înregistrări, cum ar fi Scribe și Apache Flume, urmează o cale de împingere foarte diferită, unde datele sunt împinse în aval. Există avantaje și dezavantaje pentru ambele abordări. Cu toate acestea, un sistem bazat pe împingere întâmpină dificultăți în tratarea consumatorilor diversificați, deoarece brokerul controlează rata la care datele sunt transferate. Scopul este, în general, ca consumatorul să poată consuma la rata maximă posibilă; din nefericire, într-un sistem de împingere, acest lucru înseamnă că consumatorul tinde să fie copleșit atunci când rata sa de consum scade sub rata de producție (în esență, un atac de negare a serviciului). Un sistem bazat pe trageri are proprietatea mai plăcută că consumatorul pur și simplu rămâne în urmă și recuperează când poate. Acest lucru poate fi atenuat cu ajutorul unui fel de protocol de retragere, prin care consumatorul poate indica că este copleșit, dar ajustarea ratei de transfer pentru a utiliza pe deplin (dar niciodată supra-utiliza) consumatorul este mai complicată decât pare. Încercările anterioare de a construi sisteme în acest fel ne-au determinat să optăm pentru un model de tragere mai tradițional.

Un alt avantaj al unui sistem bazat pe trageri este că se pretează bine la lotarea agresivă a datelor trimise consumatorului. Un sistem bazat pe împingere trebuie să aleagă între a trimite o cerere imediat sau a acumula mai multe date și apoi a o trimite mai târziu, fără a ști dacă consumatorul în aval le va putea procesa imediat. Dacă este optimizat pentru o latenta mică, acest lucru va duce la trimiterea unui singur mesaj la un moment dat, doar pentru a se constata că transferul este oricum amortizat, ceea ce este ineficient. Un design bazat pe trageri rezolvă acest lucru, deoarece consumatorul întotdeauna trage toate mesajele disponibile după poziția sa curentă în jurnal (sau până la o dimensiune maximă configurabilă). Prin urmare, obținem lotare optimă fără a introduce întârzieri inutile.

Deficiența unui sistem bazat pe trageri naiv este că, dacă brokerul nu are date, consumatorul poate ajunge să facă polling într-o buclă strânsă, așteptând efectiv datele să sosească. Pentru a evita acest lucru, avem parametri în cererea noastră de tragere care permit consumatorului să blocheze într-un „long poll”, așteptând până când datele sosesc (și opțional așteptând până când este disponibil un anumit număr de bytes pentru a asigura dimensiuni mari de transfer).

Se pot imagina și alte design-uri posibile care să fie doar trageri, de la cap la cap. Producătorul ar scrie local într-un jurnal local, iar brokerii ar trage de la aceasta cu consumatorii tragând de la ei. Un tip similar de producător „store-and-forward” este adesea propus. Acest lucru este intrigant, dar am simțit că nu se potrivește foarte bine pentru cazurile noastre de utilizare  cu mii de producători. Experiența noastră în rularea sistemelor persistente de date la scară ne-a făcut să credem că implicarea a mii de discuri în sistem peste multe aplicații nu ar face lucrurile mai fiabile și ar fi un coșmar de operat. Și în practică am constatat că putem rula o conductă cu acorduri stricte la scară mare fără a avea nevoie de persistența producătorului.

## Poziția Consumatorului
Urmărirea a ceea ce a fost consumat este, surprinzător, un

ul dintre punctele cheie de performanță ale unui sistem de mesagerie. Majoritatea sistemelor de mesagerie păstrează metadate despre ce mesaje au fost consumate pe broker. Adică, pe măsură ce un mesaj este dat unui consumator, brokerul înregistrează fie acel fapt local imediat, fie poate aștepta o confirmare din partea consumatorului. Aceasta este o alegere destul de intuitivă și, de fapt, pentru un server pe o singură mașină, nu este clar unde altundeva ar putea merge acest stadiu. Deoarece structurile de date folosite pentru stocare în multe sisteme de mesagerie nu scalează bine, aceasta este, de asemenea, o alegere pragmatică - deoarece brokerul știe ce a fost consumat, îl poate șterge imediat, menținând dimensiunea datelor mici.

Ceea ce poate să nu fie evident este că a ajunge la un acord între broker și consumator cu privire la ceea ce a fost consumat nu este o problemă trivială. Dacă brokerul înregistrează un mesaj ca fiind consumat imediat de fiecare dată când este dat pe rețea, atunci dacă consumatorul nu reușește să proceseze mesajul (spunem că din cauza că crash-ează sau că solicitarea expiră sau orice alt motiv) acel mesaj va fi pierdut. Pentru a rezolva această problemă, multe sisteme de mesagerie adaugă o funcție de confirmare, ceea ce înseamnă că mesajele sunt marcate doar ca trimise, nu consumate, atunci când sunt trimise; brokerul așteaptă o confirmare specifică de la consumator pentru a înregistra mesajul ca fiind consumat. Această strategie rezolvă problema pierderii mesajelor, dar creează probleme noi. În primul rând, dacă consumatorul procesează mesajul, dar eșuează înainte să poată trimite o confirmare, atunci mesajul va fi consumat de două ori. A doua problemă se referă la performanță, acum brokerul trebuie să păstreze mai multe stări despre fiecare mesaj (mai întâi pentru a-l bloca astfel încât să nu fie dat a doua oară și apoi pentru a-l marca ca fiind consumat permanent, astfel încât să poată fi eliminat). Problemele dificile trebuie abordate, cum ar fi ce să facem cu mesajele care sunt trimise, dar niciodată confirmate.

Kafka gestionează acest lucru în mod diferit. Subiectul nostru este împărțit într-un set de partiții cu ordin total, fiecare dintre ele este consumată de exact un consumator în cadrul fiecărui grup de consumatori abonat la un moment dat. Acest lucru înseamnă că poziția unui consumator în fiecare partiție este doar un singur număr, offsetul următorului mesaj de consumat. Acest lucru face ca starea despre ce a fost consumat să fie foarte mică, doar un număr pentru fiecare partiție. Această stare poate fi verificată periodic. Acest lucru face echivalentul confirmărilor de mesaje foarte ieftin.

Există și un beneficiu secundar al acestei decizii. Un consumator poate să deruleze deliberat înapoi la un offset vechi și să reconsume date. Acest lucru încalcă contractul comun al unei cozi, dar se dovedește a fi o caracteristică esențială pentru mulți consumatori. De exemplu, dacă codul consumatorului are o eroare și este descoperit după ce unele mesaje sunt consumate, consumatorul poate să reconsume acele mesaje odată ce eroarea este remediată.

## Încărcare Offline a Datelor
Persistența scalabilă permite posibilitatea consumatorilor care consumă doar periodic, cum ar fi încărcările de date în lot care încarcă periodic date într-un sistem offline precum Hadoop sau un depozit de date relațional.
În cazul Hadoop, paralelizăm încărcarea datelor prin divizarea încărcării pe sarcini individuale de hartă, câte una pentru fiecare combinație nod/subiect/partiție, permițând un paralelism complet în încărcare. Hadoop furnizează gestionarea sarcinilor, iar sarcinile care eșuează se pot reporni fără pericolul unor date duplicate - ele repornesc pur și simplu de la poziția lor originală.

## Membrii Statici
Membrii statici au ca scop îmbunătățirea disponibilității aplicațiilor de flux, grupurilor de consumatori și altor aplicații construite pe protocolul de reechilibrare a grupurilor. Protocolul de reechilibrare se bazează pe coordonatorul de grup pentru a aloca id-uri de entitate membrilor grupului. Aceste id-uri generate sunt efemere și se schimbă atunci când membrii se restartează și se alătură din nou. Pentru aplicațiile bazate pe consumatori, această „membrie dinamică” poate provoca o proporție mare de sarcini repartizate altor instanțe în timpul operațiunilor administrative, cum ar fi implementările de cod, actualizările de configurare și restarturile periodice. Pentru aplicațiile cu stări mari, sarcinile amestecate au nevoie de mult timp pentru a-și recupera stările locale înainte de procesare și cauzează indisponibilitatea parțială sau totală a aplicațiilor. Motivat de această observație, protocolul de gestionare a grupurilor din Kafka permite membrilor grupului să furnizeze id-uri de entitate persistente. Apartenența la grup rămâne neschimbată pe baza acestor id-uri, astfel încât nicio reechilibrare nu va fi declanșată. Dacă doriți să utilizați o membr

u static:

- Actualizați atât clusterul de brokeri, cât și aplicațiile client la versiunea 2.3 sau ulterioară și asigurați-vă că brokerii actualizați utilizează inter.broker.protocol.version de 2.3 sau ulterior.
- Setați configurația `ConsumerConfig#GROUP_INSTANCE_ID_CONFIG` la o valoare unică pentru fiecare instanță a consumatorului în cadrul unui grup.
- Pentru aplicațiile Kafka Streams, este suficient să setați un `ConsumerConfig#GROUP_INSTANCE_ID_CONFIG` unic per instanță KafkaStreams, independent de numărul de fire de utilizate pentru o instanță.
- Dacă brokerul este pe o versiune mai veche decât 2.3, dar alegeți să setați `ConsumerConfig#GROUP_INSTANCE_ID_CONFIG` la nivelul clientului, aplicația va detecta versiunea brokerului și apoi va genera o excepție UnsupportedException. Dacă configurați accidental id-uri duplicate pentru diferite instanțe, un mecanism de îngrădire pe partea brokerului va informa clientul duplicat să se oprească imediat, declanșând o org.apache.kafka.common.errors.FencedInstanceIdException. Pentru mai multe detalii, consultați KIP-345.
